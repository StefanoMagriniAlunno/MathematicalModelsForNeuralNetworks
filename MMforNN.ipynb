{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8W1uz1F6gxl_"
      },
      "source": [
        "# Introduction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 10100,
          "status": "ok",
          "timestamp": 1730540983339,
          "user": {
            "displayName": "stefano magrini alunno",
            "userId": "07341354876822795171"
          },
          "user_tz": -60
        },
        "id": "xRtYH0leMrmg",
        "outputId": "a53ef77d-8cd9-4fb5-f8fc-78908b0f4296"
      },
      "outputs": [],
      "source": [
        "# @title packages and versions\n",
        "\n",
        "# common packages\n",
        "import os\n",
        "from typing import Callable, List, Tuple\n",
        "from tqdm import notebook\n",
        "\n",
        "import torch\n",
        "print(f\"{torch.__version__=}\")\n",
        "from torch import nn\n",
        "from torch.nn import functional\n",
        "from torch import optim\n",
        "from torch.nn.modules import loss\n",
        "from torch.utils import data\n",
        "\n",
        "import torchvision\n",
        "print(f\"{torchvision.__version__=}\")\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "\n",
        "print(f\"{torch.cuda.is_available()=}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"{torch.cuda.device_count()=}\")\n",
        "    for i in range(torch.cuda.device_count()):\n",
        "        print(f\"{torch.cuda.get_device_name(i)=}\")\n",
        "        print(f\"{torch.cuda.get_device_capability(i)=}\")\n",
        "        print(f\"{torch.cuda.get_device_properties(i)=}\")\n",
        "print(f\"{torch.get_num_threads()=}\")\n",
        "\n",
        "\n",
        "# other packages\n",
        "from PIL import Image\n",
        "import numpy\n",
        "from matplotlib import pyplot\n",
        "from matplotlib import animation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 66420,
          "status": "ok",
          "timestamp": 1730541049756,
          "user": {
            "displayName": "stefano magrini alunno",
            "userId": "07341354876822795171"
          },
          "user_tz": -60
        },
        "id": "V_gZgZYGMsrR",
        "outputId": "b3e127a8-aa89-4cf6-b3e0-528aa03757c3"
      },
      "outputs": [],
      "source": [
        "# @title variables\n",
        "data_path = 'data'\n",
        "contents_path = os.path.join(data_path, '.contents')\n",
        "models_path = os.path.join(data_path, 'models')\n",
        "out_path = os.path.join(data_path, 'out')\n",
        "mnist_contents = os.path.join(contents_path, 'MNIST')\n",
        "mnist_models = os.path.join(models_path, 'MNIST')\n",
        "\n",
        "# download data\n",
        "datasets.MNIST(mnist_contents, train=True, download=True)\n",
        "datasets.MNIST(mnist_contents, train=False, download=True)\n",
        "\n",
        "if not os.path.exists(mnist_models):\n",
        "    os.makedirs(mnist_models)\n",
        "\n",
        "if not os.path.exists(out_path):\n",
        "    os.makedirs(out_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p7CunGhdtkEU"
      },
      "source": [
        "# Definitions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title DeepHNN\n",
        "\n",
        "class DeepHNN(nn.Module):\n",
        "\n",
        "    channels: int\n",
        "    features: int\n",
        "    neurons: int\n",
        "    deep: int\n",
        "    iterations: int\n",
        "\n",
        "    _logbeta: nn.Parameter\n",
        "    _bias: nn.Parameter\n",
        "    _patterns: nn.Parameter\n",
        "\n",
        "    def __init__(\n",
        "            self,\n",
        "            channels: int,\n",
        "            features: int,\n",
        "            deep: int,\n",
        "            neurons: int,\n",
        "            iterations: int = 1,\n",
        "            beta_trainable: bool = True,\n",
        "            bias_trainable: bool = True,\n",
        "            patterns_trainable: bool = True,\n",
        "        ) -> None:\n",
        "\n",
        "        super(DeepHNN, self).__init__()\n",
        "\n",
        "        assert channels > 0, \"channels must be greater than 0\"\n",
        "        assert features > 0, \"features must be greater than 0\"\n",
        "        assert deep > 0, \"deep must be greater than 0\"\n",
        "        assert neurons > 0, \"neurons must be greater than 0\"\n",
        "        assert iterations >= 0, \"number of iterations must be greater than or equal to 0\"\n",
        "\n",
        "        self.channels = channels\n",
        "        self.features = features\n",
        "        self.deep = deep\n",
        "        self.neurons = neurons\n",
        "        self.iterations = iterations\n",
        "\n",
        "        if beta_trainable:\n",
        "            self._logbeta = nn.Parameter(torch.zeros(channels), requires_grad=beta_trainable)\n",
        "        else:\n",
        "            self._logbeta = nn.Parameter(torch.zeros(channels), requires_grad=beta_trainable)\n",
        "        self._patterns = nn.Parameter(torch.tanh(torch.randn(channels, deep*features, neurons)), requires_grad=patterns_trainable)\n",
        "        if bias_trainable:\n",
        "            self._bias = nn.Parameter(torch.randn(channels, features), requires_grad=bias_trainable)\n",
        "        else:\n",
        "            self._bias = nn.Parameter(torch.zeros(channels, features), requires_grad=bias_trainable)\n",
        "\n",
        "    def update_patterns(self, patterns: torch.Tensor, trainable: bool|None=None) -> None:\n",
        "        \n",
        "        assert patterns.shape == self._patterns.data.shape, \"shape of patterns must be the same as the current patterns\"\n",
        "\n",
        "        _trainable: bool\n",
        "        if trainable is None:\n",
        "            _trainable = self._patterns.requires_grad\n",
        "\n",
        "        self._patterns = nn.Parameter(\n",
        "            patterns.clone().detach().requires_grad_(_trainable),\n",
        "            requires_grad=_trainable\n",
        "        )\n",
        "\n",
        "    def update_beta(self, beta: torch.Tensor, trainable: bool|None=None) -> None:\n",
        "\n",
        "        assert beta.shape == self._logbeta.data.shape, \"shape of beta must be the same as the current beta\"\n",
        "        assert torch.all(beta > 0), \"all elements of beta must be greater than 0\"\n",
        "\n",
        "        _trainable: bool\n",
        "        if trainable is None:\n",
        "            _trainable = self._logbeta.requires_grad\n",
        "\n",
        "        self._logbeta = nn.Parameter(\n",
        "            torch.log(beta).clone().detach().to(self._logbeta.device).requires_grad_(_trainable),\n",
        "            requires_grad=_trainable\n",
        "        )\n",
        "\n",
        "    def update_bias(self, bias: torch.Tensor, trainable: bool|None=None) -> None:\n",
        "\n",
        "        assert bias.shape == self._bias.data.shape, \"shape of bias must be the same as the current bias\"\n",
        "\n",
        "        _trainable: bool\n",
        "        if trainable is None:\n",
        "            _trainable = self._bias.requires_grad\n",
        "\n",
        "        self._bias = nn.Parameter(\n",
        "            torch.log(bias).clone().detach().to(self._bias).requires_grad_(_trainable),\n",
        "            requires_grad=_trainable\n",
        "        )\n",
        "\n",
        "    def get_patterns(self) -> torch.Tensor:\n",
        "        return self._patterns.clone().detach().view(self.channels, self.features, self.deep, self.neurons)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "\n",
        "        # Shape of x must be (batch, channels, neurons)\n",
        "    \n",
        "        L = torch.exp(self._logbeta).view(self.channels, 1, 1) * self._patterns\n",
        "        A = torch.einsum('cin , cjn-> cij', L, self._patterns)  # i,j are logits\n",
        "        \n",
        "        # main algorithm\n",
        "        x = torch.einsum('cln, bcn -> bcl', L, x)  # get logits\n",
        "        for _ in range(self.iterations):\n",
        "            x = functional.softmax(x, dim=2)  # get probs\n",
        "            x = torch.einsum('clp, bcp -> bcl', A, x)  # get logits\n",
        "        \n",
        "        # max reduction\n",
        "        x = x.view(-1, self.channels, self.features, self.deep)\n",
        "        x = torch.max(x, dim=3).values\n",
        "        x = x + self._bias.view(1, self.channels, self.features)\n",
        "        \n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "LHBVY2HnNJZt"
      },
      "outputs": [],
      "source": [
        "# @title ConvHNN2d\n",
        "class ConvHNN2d(nn.Module):\n",
        "\n",
        "    channels_in: int\n",
        "    channels_out: int\n",
        "    kernel_size: Tuple[int, int]\n",
        "    padding: Tuple[int, int]\n",
        "    stride: Tuple[int, int]\n",
        "    dilation: Tuple[int, int]\n",
        "\n",
        "    iterations: int\n",
        "\n",
        "    _logbeta: nn.Parameter\n",
        "    _bias: nn.Parameter\n",
        "    _patterns: nn.Parameter\n",
        "\n",
        "    def __init__(\n",
        "            self,\n",
        "            channels_in: int,\n",
        "            channels_out: int,\n",
        "            kernel_size: Tuple[int, int],\n",
        "            padding: Tuple[int, int] = (0, 0),\n",
        "            stride: Tuple[int, int] = (1, 1),\n",
        "            dilation: Tuple[int, int] = (1, 1),\n",
        "            iterations: int = 1,\n",
        "            beta_trainable: bool = True,\n",
        "            patterns_trainable: bool = True,\n",
        "            bias_trainable: bool = True,\n",
        "        ) -> None:\n",
        "        super(ConvHNN2d, self).__init__()\n",
        "\n",
        "        assert channels_in > 0\n",
        "        assert channels_out > 0\n",
        "        assert kernel_size[0] > 0\n",
        "        assert kernel_size[1] > 0\n",
        "        assert padding[0] >= 0\n",
        "        assert padding[1] >= 0\n",
        "        assert stride[0] > 0\n",
        "        assert stride[1] > 0\n",
        "        assert dilation[0] > 0\n",
        "        assert dilation[1] > 0\n",
        "        assert iterations > 0\n",
        "\n",
        "        self.channels_in = channels_in\n",
        "        self.channels_out = channels_out\n",
        "        self.kernel_size = kernel_size\n",
        "        self.padding = padding\n",
        "        self.stride = stride\n",
        "        self.dilation = dilation\n",
        "        self.iterations = iterations\n",
        "\n",
        "        if beta_trainable:\n",
        "            self._logbeta = nn.Parameter(torch.randn((1,)), requires_grad=beta_trainable)\n",
        "        else:\n",
        "            self._logbeta = nn.Parameter(torch.zeros((1,)), requires_grad=beta_trainable)\n",
        "        self._patterns = nn.Parameter(torch.tanh(torch.randn(channels_out, channels_in, kernel_size[0], kernel_size[1])), requires_grad=patterns_trainable)\n",
        "        if bias_trainable:\n",
        "            self._bias = nn.Parameter(torch.randn(channels_out,), requires_grad=bias_trainable)\n",
        "        else:\n",
        "            self._bias = nn.Parameter(torch.zeros(channels_out,), requires_grad=bias_trainable)\n",
        "\n",
        "    def update_patterns(self, patterns: torch.Tensor, trainable: bool|None=None) -> None:\n",
        "        assert patterns.shape == self._patterns.data.shape\n",
        "\n",
        "        _trainable: bool\n",
        "        if trainable is None:\n",
        "            _trainable = self._patterns.requires_grad\n",
        "\n",
        "        self._patterns = nn.Parameter(\n",
        "            patterns.clone().detach().to(self._patterns.device).requires_grad_(_trainable),\n",
        "            requires_grad=_trainable)\n",
        "\n",
        "    def update_beta(self, beta: float, trainable: bool|None=None) -> None:\n",
        "        assert beta > 0\n",
        "\n",
        "        _trainable: bool\n",
        "        if trainable is None:\n",
        "            _trainable = self._logbeta.requires_grad\n",
        "\n",
        "        self._logbeta.data = nn.Parameter(\n",
        "            torch.log(torch.tensor(beta)).clone().detach().to(self._logbeta.device).requires_grad_(_trainable),\n",
        "            requires_grad=_trainable)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "\n",
        "        # Shape of x must be (batch, channels_in, #, #)\n",
        "        \n",
        "        weight_loop = (\n",
        "            torch.exp(self._logbeta)\n",
        "            * torch.einsum(\n",
        "                'in, jn -> ij',  # i,j are logits (channels_out)\n",
        "                self._patterns.view(self.channels_out, -1),\n",
        "                self._patterns.view(self.channels_out, -1)\n",
        "            )\n",
        "        ).view(self.channels_out, self.channels_out, 1, 1)\n",
        "\n",
        "        x = nn.functional.conv2d(\n",
        "            x,\n",
        "            torch.exp(self._logbeta) * self._patterns,\n",
        "            stride=self.stride,\n",
        "            padding=self.padding,\n",
        "            dilation=self.dilation,\n",
        "        )\n",
        "        for _ in range(self.iterations):\n",
        "            x = nn.functional.softmax(x, dim=1)\n",
        "            x = nn.functional.conv2d(x, weight_loop)\n",
        "\n",
        "        return x + self._bias.view(1,self.channels_out,1,1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P4UD9t5ARvPw"
      },
      "outputs": [],
      "source": [
        "# @title VHNN\n",
        "\n",
        "class VHNN(nn.Module):\n",
        "\n",
        "    channels : int\n",
        "    features : int\n",
        "    neurons : int\n",
        "\n",
        "    iterations : int\n",
        "\n",
        "    _logbeta : nn.Parameter\n",
        "    _lognoise : nn.Parameter\n",
        "    _patterns : nn.Parameter\n",
        "\n",
        "    def __init__(\n",
        "            self,\n",
        "            channels: int,\n",
        "            features: int,\n",
        "            neurons: int,\n",
        "            iterations: int = 1,\n",
        "            beta_trainable: bool = True,\n",
        "            patterns_trainable: bool = True,\n",
        "            noise_trainable: bool = True,\n",
        "        ) -> None:\n",
        "        super(VHNN, self).__init__()\n",
        "\n",
        "        assert channels > 0\n",
        "        assert features > 0\n",
        "        assert neurons > 0\n",
        "        assert iterations > 0\n",
        "\n",
        "        self.channels = channels\n",
        "        self.features = features\n",
        "        self.neurons = neurons\n",
        "        self.iterations = iterations\n",
        "\n",
        "        if beta_trainable:\n",
        "            self._logbeta = nn.Parameter(torch.zeros(channels), requires_grad=beta_trainable)\n",
        "        else:\n",
        "            self._logbeta = nn.Parameter(torch.zeros(channels), requires_grad=beta_trainable)\n",
        "        self._patterns = nn.Parameter(torch.tanh(torch.randn(channels, features, neurons)), requires_grad=patterns_trainable)\n",
        "        if noise_trainable:\n",
        "            self._lognoise = nn.Parameter(torch.randn((channels,))-3, requires_grad=noise_trainable)\n",
        "        else:\n",
        "            self._lognoise = nn.Parameter(torch.zeros((channels,))-3, requires_grad=noise_trainable)\n",
        "\n",
        "    def update_patterns(self, patterns: torch.Tensor, trainable: bool|None=None) -> None:\n",
        "        \n",
        "        assert patterns.shape == self._patterns.data.shape, \"shape of patterns must be the same as the current patterns\"\n",
        "\n",
        "        _trainable: bool\n",
        "        if trainable is None:\n",
        "            _trainable = self._patterns.requires_grad\n",
        "\n",
        "        self._patterns = nn.Parameter(\n",
        "            patterns.clone().detach().requires_grad_(_trainable),\n",
        "            requires_grad=_trainable\n",
        "        )\n",
        "\n",
        "    def update_beta(self, beta: torch.Tensor, trainable: bool|None=None) -> None:\n",
        "\n",
        "        assert beta.shape == self._logbeta.data.shape, \"shape of beta must be the same as the current beta\"\n",
        "        assert torch.all(beta > 0), \"all elements of beta must be greater than 0\"\n",
        "\n",
        "        _trainable: bool\n",
        "        if trainable is None:\n",
        "            _trainable = self._logbeta.requires_grad\n",
        "\n",
        "        self._logbeta = nn.Parameter(\n",
        "            torch.log(beta).clone().detach().to(self._logbeta.device).requires_grad_(_trainable),\n",
        "            requires_grad=_trainable\n",
        "        )\n",
        "\n",
        "    def update_noise(self, noise: torch.Tensor, trainable: bool|None=None) -> None:\n",
        "\n",
        "        assert noise.shape == self._lognoise.data.shape, \"shape of noise must be the same as the current noise\"\n",
        "\n",
        "        _trainable: bool\n",
        "        if trainable is None:\n",
        "            _trainable = self._lognoise.requires_grad\n",
        "\n",
        "        self._lognoise = nn.Parameter(\n",
        "            torch.log(noise).clone().detach().to(self._lognoise).requires_grad_(_trainable),\n",
        "            requires_grad=_trainable\n",
        "        )\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "\n",
        "        x = x.view(-1, self.channels, self.neurons)\n",
        "\n",
        "        L = torch.exp(self._logbeta/2).view(-1, 1, 1) * self._patterns\n",
        "\n",
        "        x = torch.exp(self._logbeta/2).view(1, -1, 1) * x\n",
        "        for _ in range(self.iterations):\n",
        "            x = torch.einsum('cfn, bcn -> bcf', L, x)\n",
        "            x = nn.functional.softmax(x, dim=2)\n",
        "            epsilon = torch.randn_like(x, device=x.device, requires_grad=False)\n",
        "            xdet = x.detach().requires_grad(False)\n",
        "            x = x + torch.exp(self._lognoise).view(1,-1,1) * (xdet*(1-xdet))**0.5 * epsilon\n",
        "            x = torch.einsum('cfn, bcf -> bcn', L, x)\n",
        "\n",
        "        x = torch.exp(-self._logbeta/2).view(1, -1, 1) * x\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c8Yhrih5gxmC"
      },
      "outputs": [],
      "source": [
        "# @title ConvexMerge\n",
        "\n",
        "class ConvexMerge(nn.Module):\n",
        "\n",
        "    _weights: nn.Parameter  # weights\n",
        "    channels: int  # number of input channels\n",
        "    classes: int  # number of classes\n",
        "    features_out: int  # number of output features\n",
        "    features_in: int  # number of input features\n",
        "\n",
        "\n",
        "    def __init__(self, channels: int, classes: int, features_out: int, features_in: int) -> None:\n",
        "        super(ConvexMerge, self).__init__()\n",
        "\n",
        "        assert channels > 0\n",
        "        assert classes > 0\n",
        "        assert features_out > 0\n",
        "        assert features_in > 0\n",
        "\n",
        "        self._weights = nn.Parameter(torch.randn(channels, classes, features_out, features_in))\n",
        "\n",
        "        self.channels = channels\n",
        "        self.classes = classes\n",
        "        self.features_out = features_out\n",
        "        self.features_in = features_in\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "\n",
        "        x = x.view(x.shape[0], self.channels, self.classes, self.features_in)\n",
        "\n",
        "        return torch.einsum('kcoi, bkci -> bkco', nn.functional.softmax(self._weights, dim=-1), x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y54np6ogNTps"
      },
      "outputs": [],
      "source": [
        "# @title trainer_classification\n",
        "def trainer_classification(\n",
        "        model: nn.Module,\n",
        "        data_loader: data.DataLoader,\n",
        "        loss_fn: callable,\n",
        "        reg_fn: callable,\n",
        "        optimizer,\n",
        "        n_epochs: int,\n",
        "        input_converter: None|Callable[[torch.Tensor], torch.Tensor] = None,\n",
        "        output_converter: None|Callable[[torch.Tensor], torch.Tensor] = None,\n",
        "        device: torch.device = torch.device(\"cpu\")\n",
        "    ) -> Tuple[List[float], List[float], List[float]]:\n",
        "    torch.cuda.empty_cache()\n",
        "    model.to(device)\n",
        "    model.train()\n",
        "\n",
        "    accuracy : List[float] = []\n",
        "    loss : List[float] = []\n",
        "    reg : List[float] = []\n",
        "    total : List[float] = []\n",
        "\n",
        "    progressBar_epoch = notebook.tqdm(\n",
        "        range(n_epochs),\n",
        "        desc=\"Epochs\",\n",
        "        leave=False)\n",
        "    for _ in progressBar_epoch:\n",
        "\n",
        "\n",
        "        x: torch.Tensor\n",
        "        y: torch.Tensor\n",
        "\n",
        "        accuracy_epoch = 0.0\n",
        "        loss_epoch = 0.0\n",
        "        reg_epoch = 0.0\n",
        "        total_epoch = 0.0\n",
        "\n",
        "        progressBar_batch = notebook.tqdm(\n",
        "            data_loader,\n",
        "            desc=\"Batches\",\n",
        "            total=len(data_loader),\n",
        "            leave=False)\n",
        "        for x, y in progressBar_batch:\n",
        "\n",
        "            x, y = x.to(device), y.to(device)\n",
        "\n",
        "            if input_converter != None:\n",
        "                x = input_converter(x)\n",
        "            if output_converter != None:\n",
        "                y = output_converter(y)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            _y = model(x)\n",
        "            accuracy_batch = torch.count_nonzero(torch.argmax(_y, dim=1) == y) / y.shape[0]\n",
        "            batch_reg: torch.Tensor = reg_fn(model)\n",
        "            batch_loss: torch.Tensor = loss_fn(_y, y)\n",
        "            batch_total: torch.Tensor = batch_loss + batch_reg\n",
        "\n",
        "            batch_total.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            accuracy_epoch += accuracy_batch.item()\n",
        "            loss_epoch += batch_loss.item()\n",
        "            reg_epoch += batch_reg.item()\n",
        "            total_epoch += batch_reg.item()+batch_loss.item()\n",
        "\n",
        "        accuracy.append(accuracy_epoch / len(data_loader))\n",
        "        loss.append(loss_epoch / len(data_loader))\n",
        "        reg.append(reg_epoch / len(data_loader))\n",
        "        total.append(total_epoch / len(data_loader))\n",
        "\n",
        "        progressBar_epoch.set_postfix(\n",
        "            loss= loss[-1],\n",
        "            reg= reg[-1],\n",
        "            accuracy= accuracy[-1],\n",
        "        )\n",
        "\n",
        "    return accuracy, loss, reg, total"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Da2ANpPYRvPw"
      },
      "outputs": [],
      "source": [
        "# @title trainer_autoencoder\n",
        "\n",
        "def trainer_autoencoder(\n",
        "        model: nn.Module,\n",
        "        data_loader: data.DataLoader,\n",
        "        loss_fn: callable,\n",
        "        reg_fn: callable,\n",
        "        optimizer,\n",
        "        n_epochs: int,\n",
        "        input_converter: None|Callable[[torch.Tensor], torch.Tensor] = None,\n",
        "        output_converter: None|Callable[[torch.Tensor], torch.Tensor] = None,\n",
        "        device: torch.device = torch.device(\"cpu\")\n",
        "    ) -> Tuple[List[float], List[float], List[float]]:\n",
        "    torch.cuda.empty_cache()\n",
        "    model.to(device)\n",
        "    model.train()\n",
        "\n",
        "    loss : List[float] = []\n",
        "    reg : List[float] = []\n",
        "    total : List[float] = []\n",
        "\n",
        "    progressBar_epoch = notebook.tqdm(\n",
        "        range(n_epochs),\n",
        "        desc=\"Epochs\",\n",
        "        leave=False)\n",
        "    for _ in progressBar_epoch:\n",
        "\n",
        "        x: torch.Tensor\n",
        "\n",
        "        loss_epoch = 0.0\n",
        "        reg_epoch = 0.0\n",
        "        total_epoch = 0.0\n",
        "\n",
        "        progressBar_batch = notebook.tqdm(\n",
        "            data_loader,\n",
        "            desc=\"Batches\",\n",
        "            total=len(data_loader),\n",
        "            leave=False)\n",
        "        for x, _ in progressBar_batch:\n",
        "\n",
        "            x = x.to(device)\n",
        "\n",
        "            y = x.clone()\n",
        "            if input_converter != None:\n",
        "                x = input_converter(x)\n",
        "            if output_converter != None:\n",
        "                y = output_converter(y)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            _y = model(x)\n",
        "            batch_reg: torch.Tensor = reg_fn(model)\n",
        "            batch_loss: torch.Tensor = loss_fn(_y, y)\n",
        "            batch_total: torch.Tensor = batch_loss + batch_reg\n",
        "\n",
        "            batch_total.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            loss_epoch += batch_loss.item()\n",
        "            reg_epoch += batch_reg.item()\n",
        "            total_epoch += batch_reg.item()+batch_loss.item()\n",
        "\n",
        "        loss.append(loss_epoch / len(data_loader))\n",
        "        reg.append(reg_epoch / len(data_loader))\n",
        "        total.append(total_epoch / len(data_loader))\n",
        "\n",
        "        progressBar_epoch.set_postfix(\n",
        "            loss= loss[-1],\n",
        "            reg= reg[-1],\n",
        "        )\n",
        "\n",
        "    return loss, reg, total"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "GgXobq3eNY1q"
      },
      "outputs": [],
      "source": [
        "# @title tester_classification\n",
        "def tester_classification(model: nn.Module, data_loader: data.DataLoader, device: torch.device) -> float:\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        x: torch.Tensor\n",
        "        y: torch.Tensor\n",
        "\n",
        "        for x, y in notebook.tqdm(data_loader, desc=\"Batches\", leave=False):\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            _y = model(x)\n",
        "            _, predicted = torch.max(_y, 1)\n",
        "            total += y.size(0)\n",
        "            correct += (predicted == y).sum().item()\n",
        "\n",
        "    return correct / total"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1rZ4iHAURvPx"
      },
      "outputs": [],
      "source": [
        "# @title tester_autoencoder\n",
        "\n",
        "def tester_autoencoder(\n",
        "        model: nn.Module,\n",
        "        data_loader: data.DataLoader,\n",
        "        device: torch.device,\n",
        "        input_converter: None|Callable[[torch.Tensor], torch.Tensor] = None,\n",
        "        output_converter: None|Callable[[torch.Tensor], torch.Tensor] = None,\n",
        "    ) -> float:\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    total = 0.0\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        x: torch.Tensor\n",
        "\n",
        "        for x, _ in notebook.tqdm(data_loader, desc=\"Batches\", leave=False):\n",
        "\n",
        "            x = x.to(device)\n",
        "            y = x.clone()\n",
        "            if input_converter != None:\n",
        "                x = input_converter(x)\n",
        "            if output_converter != None:\n",
        "                y = output_converter(y)\n",
        "\n",
        "            _y = model(x)\n",
        "            loss = nn.functional.mse_loss(_y, y, reduction='mean')\n",
        "            total += loss.item()\n",
        "\n",
        "    return total / len(data_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wc7FkNM3Nfc9"
      },
      "source": [
        "# MNIST"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "n4uKGcgdNglq"
      },
      "outputs": [],
      "source": [
        "# @title Used transform\n",
        "\n",
        "transform=transforms.Compose(\n",
        "    [\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Grayscale(),\n",
        "        transforms.RandomAffine(\n",
        "            degrees=5, translate=(0.1, 0.1), scale=(0.9, 1.1), shear=10\n",
        "        ),\n",
        "        transforms.ColorJitter(contrast=(0.9, 1.5)),\n",
        "        transforms.Pad(2),  # pad to 32x32\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "executionInfo": {
          "elapsed": 24485,
          "status": "ok",
          "timestamp": 1730541074237,
          "user": {
            "displayName": "stefano magrini alunno",
            "userId": "07341354876822795171"
          },
          "user_tz": -60
        },
        "id": "XdhY_iR0PxWF",
        "outputId": "14ec764c-efd7-48ab-b6dd-c7acf2c2675c"
      },
      "outputs": [],
      "source": [
        "# @title Load patterns\n",
        "patterns = torch.empty(30, 32, 32)\n",
        "for i in range(10):\n",
        "    for j in range(3):\n",
        "        img = Image.open(f\"{mnist_models}/pattern{i}_{j}.png\").convert('L')\n",
        "        npimg = numpy.array(img)\n",
        "        patterns[i*3+j] = torch.tensor(npimg)\n",
        "\n",
        "patterns = patterns.unsqueeze(1).float() / 255.0\n",
        "patterns = 2.0 * patterns - 1.0\n",
        "\n",
        "# show patterns\n",
        "fig, axs = pyplot.subplots(10, 3, figsize=(10, 30))\n",
        "for i in range(10):\n",
        "    for j in range(3):\n",
        "        axs[i, j].imshow(patterns[i*3+j,0], cmap='gray', vmin=-1, vmax=1)\n",
        "        axs[i, j].axis('off')\n",
        "pyplot.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "executionInfo": {
          "elapsed": 1024,
          "status": "ok",
          "timestamp": 1730541075259,
          "user": {
            "displayName": "stefano magrini alunno",
            "userId": "07341354876822795171"
          },
          "user_tz": -60
        },
        "id": "l13C1GugSO_T",
        "outputId": "ca366ee5-d247-4364-ff44-11c542ab5dcf"
      },
      "outputs": [],
      "source": [
        "# @title Testing Hopfield using patterns\n",
        "model = [\n",
        "    DeepHNN(1, 30, 1, 32*32, iterations=1, beta_trainable=False, patterns_trainable=False)\n",
        "    for _ in range(1)\n",
        "]\n",
        "for m in model:\n",
        "    m.update_patterns(patterns.view(1, 30, -1))\n",
        "    m.to(torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
        "\n",
        "model[0].update_beta(torch.ones(1)*0.0001)\n",
        "\n",
        "test_set = datasets.MNIST(mnist_contents, train=False, download=False, transform=transform)\n",
        "data_loader = data.DataLoader(test_set, batch_size=1, shuffle=True)\n",
        "\n",
        "# get a batch of images\n",
        "x = patterns[torch.randint(0, 30, (6,))].clone().detach().to(torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
        "\n",
        "fig, axs = pyplot.subplots(2, 6, figsize=(6*2, 2*2))\n",
        "for i in range(2):\n",
        "    for j in range(6):\n",
        "        img = x[j].clone().detach().to(x.device)\n",
        "        axs[i, j].imshow(img[0].cpu().detach().numpy(), cmap='gray', vmin=-1, vmax=1)\n",
        "        axs[i, j].axis('off')\n",
        "    x = x.view(6, 1, -1)\n",
        "    x = model[0](x)\n",
        "    x = functional.softmax(x, dim=2)\n",
        "    x = torch.einsum('bcl, cln -> bcn', x, model[0]._patterns)\n",
        "    x = x.view(6, 1, 32, 32)\n",
        "pyplot.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "duwdZqjVgxmE"
      },
      "source": [
        "## Simple experiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "ZKDQZxGCS6Mw"
      },
      "outputs": [],
      "source": [
        "# @title training\n",
        "train_set = datasets.MNIST(mnist_contents, train=True, download=False, transform=transform)\n",
        "train_loader = data.DataLoader(train_set, batch_size=16_384, shuffle=True)\n",
        "\n",
        "class MyModel(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(MyModel, self).__init__()\n",
        "        self.Hopfield = DeepHNN(1, 10, 3, 32*32, iterations=1, beta_trainable=False)\n",
        "\n",
        "        self.Hopfield.update_patterns(patterns.view(1, 30, -1))\n",
        "        self.Hopfield.update_beta(torch.ones(1)*0.07)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        x = x.view(x.shape[0], 1, -1)\n",
        "        x = nn.BatchNorm1d(1, affine=False).to(x.device)(x)\n",
        "        x = self.Hopfield(x)\n",
        "        x = x.view(x.shape[0], -1)\n",
        "        return x\n",
        "\n",
        "model = MyModel()\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "# (ignorable function)\n",
        "def reg_fn(model: MyModel) -> torch.Tensor:\n",
        "    return torch.tensor(0.0)\n",
        "\n",
        "accuracy, loss, reg, total = trainer_classification(\n",
        "    model,\n",
        "    train_loader,\n",
        "    loss_fn,\n",
        "    reg_fn,\n",
        "    optimizer,\n",
        "    40,\n",
        "    device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        ")\n",
        "\n",
        "fig, axs = pyplot.subplots(1, 2, figsize=(20, 10))\n",
        "axs[0].bar(range(len(total)), total, label=\"Total\")\n",
        "axs[0].bar(range(len(loss)), loss, label=\"Loss\")\n",
        "axs[0].legend()\n",
        "axs[0].set_title(\"Loss and Total\")\n",
        "axs[0].set_xlabel(\"Epoch\")\n",
        "axs[1].plot(range(len(accuracy)), accuracy, label=\"Accuracy\")\n",
        "axs[1].legend()\n",
        "axs[1].set_title(\"Accuracy\")\n",
        "axs[1].set_xlabel(\"Epoch\")\n",
        "pyplot.savefig(f\"{out_path}/MNIST_SimpleExperiment.png\", dpi=300)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "zMhxGtIgTPch"
      },
      "outputs": [],
      "source": [
        "# @title testing\n",
        "test_set = datasets.MNIST(mnist_contents, train=False, download=False, transform=transform)\n",
        "test_loader = data.DataLoader(test_set, batch_size=16_384, shuffle=False)\n",
        "\n",
        "tester_classification(model, test_loader, torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "_JMdckJUTbqI"
      },
      "outputs": [],
      "source": [
        "# @title analysis\n",
        "model.to(torch.device(\"cpu\"))\n",
        "\n",
        "print(f\" beta = {torch.exp(model.Hopfield._logbeta.data)}\")\n",
        "print(f\" bias = {model.Hopfield._bias.data.view(10,)}\")\n",
        "\n",
        "found_patterns = model.Hopfield._patterns.data.view(10, 3, 32, 32).clone().to('cpu').numpy()\n",
        "\n",
        "fig, axs = pyplot.subplots(10, 3, figsize=(3*3, 10*3))\n",
        "\n",
        "for i in range(10):\n",
        "    for j in range(3):\n",
        "        axs[i, j].imshow(found_patterns[i][j], cmap='gray', vmin=found_patterns.min(), vmax=found_patterns.max())\n",
        "        axs[i, j].axis('off')\n",
        "\n",
        "pyplot.savefig(f\"{out_path}/MNIST_patterns.png\", dpi=300)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ra5HbswhgxmE"
      },
      "source": [
        "## Hopfield as MLP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2-yFFX97gxmF"
      },
      "outputs": [],
      "source": [
        "# @title training\n",
        "train_set = datasets.MNIST(mnist_contents, train=True, download=False, transform=transform)\n",
        "train_loader = data.DataLoader(train_set, batch_size=2_048, shuffle=True)\n",
        "\n",
        "channels = 5\n",
        "deep = 5\n",
        "features = 10\n",
        "\n",
        "class MyModel(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(MyModel, self).__init__()\n",
        "        self.cnn = nn.Sequential(\n",
        "            nn.Conv2d(1, channels, 4, stride=2, bias=False),\n",
        "        )\n",
        "        self.Hopfield = nn.Sequential(\n",
        "            nn.BatchNorm1d(channels, affine=False),\n",
        "            DeepHNN(channels, features, deep, 15*15, iterations=1),\n",
        "        )\n",
        "        self.merge = ConvexMerge(1, features, 1, channels)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        x = self.cnn(x)\n",
        "        x = x.view(x.shape[0], channels, -1)\n",
        "        x = self.Hopfield(x)\n",
        "        x = x.transpose(1, 2).view(x.shape[0],1,features,channels)\n",
        "        x = self.merge(x)\n",
        "        x = x.view(x.shape[0], features)\n",
        "        return x\n",
        "\n",
        "model = MyModel()\n",
        "\n",
        "print(f\"trainable parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad)}\")\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "def reg_fn(model: MyModel) -> torch.Tensor:\n",
        "    reg = torch.tensor(0.0).to(torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
        "    for p in model.cnn.parameters():\n",
        "        reg += torch.mean(torch.abs(p))\n",
        "\n",
        "    reg += torch.max(torch.mean(model.merge._weights, dim=1)**2)\n",
        "    return 0.01*reg\n",
        "\n",
        "accuracy: List[float] = []\n",
        "loss: List[float] = []\n",
        "reg: List[float] = []\n",
        "total: List[float] = []\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "a, l, r, t = trainer_classification(\n",
        "    model,\n",
        "    train_loader,\n",
        "    loss_fn,\n",
        "    reg_fn,\n",
        "    optimizer,\n",
        "    15,\n",
        "    device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        ")\n",
        "\n",
        "accuracy.extend(a)\n",
        "loss.extend(l)\n",
        "reg.extend(r)\n",
        "total.extend(t)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "a, l, r, t = trainer_classification(\n",
        "    model,\n",
        "    train_loader,\n",
        "    loss_fn,\n",
        "    reg_fn,\n",
        "    optimizer,\n",
        "    15,\n",
        "    device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        ")\n",
        "\n",
        "accuracy.extend(a)\n",
        "loss.extend(l)\n",
        "reg.extend(r)\n",
        "total.extend(t)\n",
        "\n",
        "fig, axs = pyplot.subplots(1, 2, figsize=(10, 5))\n",
        "axs[0].bar(range(len(total)), total, label=\"Total\")\n",
        "axs[0].bar(range(len(loss)), loss, label=\"Loss\")\n",
        "axs[0].legend()\n",
        "axs[0].set_title(\"Loss and Total\")\n",
        "axs[0].set_xlabel(\"Epoch\")\n",
        "axs[1].plot(range(len(accuracy)), accuracy, label=\"Accuracy\")\n",
        "axs[1].legend()\n",
        "axs[1].set_title(\"Accuracy\")\n",
        "axs[1].set_xlabel(\"Epoch\")\n",
        "pyplot.savefig(f\"{out_path}/MNIST_MLPExperiment.png\", dpi=300)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title testing\n",
        "test_set = datasets.MNIST(mnist_contents, train=False, download=False, transform=transform)\n",
        "test_loader = data.DataLoader(test_set, batch_size=16_384, shuffle=False)\n",
        "\n",
        "tester_classification(model, test_loader, torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "XYqV0GemgxmF"
      },
      "outputs": [],
      "source": [
        "# @title analysis: CNN kernels\n",
        "\n",
        "fig, axs = pyplot.subplots(1, channels, figsize=(3*channels, 3))\n",
        "\n",
        "for i in range(1):\n",
        "    for j in range(channels):\n",
        "        axs[j].imshow(model.cnn[0].weight[i*channels+j].detach().cpu().numpy().squeeze(), cmap='gray')\n",
        "        axs[j].axis('off')\n",
        "\n",
        "pyplot.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "TRLb9KB6gxmF"
      },
      "outputs": [],
      "source": [
        "# @title analysis: convex\n",
        "\n",
        "matrix = nn.functional.softmax(model.merge._weights[0,:,0,:], dim=-1).detach().cpu().numpy()\n",
        "\n",
        "pyplot.imshow(matrix, cmap='gray', vmin=0, vmax=1)\n",
        "pyplot.axis('off')\n",
        "\n",
        "# peso dei canali\n",
        "print(matrix.sum(axis=0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "g0oJa5g2gxmF"
      },
      "outputs": [],
      "source": [
        "# @title an example\n",
        "\n",
        "test_set = datasets.MNIST(mnist_contents, train=False, download=False, transform=transform)\n",
        "test_loader = data.DataLoader(test_set, batch_size=128, shuffle=True)\n",
        "\n",
        "# variables\n",
        "for digit in range(10):\n",
        "\n",
        "    # get an image with digit 7\n",
        "    x, y = next(iter(test_loader))\n",
        "    x = x[y == digit].to(torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
        "    y = y[y == digit].to(torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
        "\n",
        "    pyplot.imshow(x[0,0].view(32, 32).detach().cpu().numpy(), cmap='gray')\n",
        "    pyplot.axis('off')\n",
        "    pyplot.savefig(f\"{out_path}/MNIST_MLPexperiment_example{digit}_1.png\", dpi=1200)\n",
        "\n",
        "    x = model.cnn(x)\n",
        "    x = x.view(-1, channels, 15*15)\n",
        "    x = model.Hopfield[0](x)\n",
        "    fig, axs = pyplot.subplots(1, channels, figsize=(3*channels, 3))\n",
        "    for i in range(channels):\n",
        "        axs[i].imshow(x[0,i].view(15, 15).detach().cpu().numpy(), cmap='gray', vmin=-2.5, vmax=2.5)\n",
        "        axs[i].axis('off')\n",
        "    pyplot.savefig(f\"{out_path}/MNIST_MLPexperiment_example{digit}_2.png\", dpi=1200)\n",
        "\n",
        "    x = model.Hopfield[1](x).view(-1, channels, features)\n",
        "    fig, axs = pyplot.subplots(1, channels, figsize=(3*channels, 3))\n",
        "    for i in range(channels):\n",
        "        axs[i].bar(range(features), x[0,i,:].detach().cpu().numpy())\n",
        "        axs[i].get_xaxis().set_visible(False)\n",
        "        axs[i].set_ylim(x[0].min().item()-1, x[0].max().item()+1)\n",
        "    pyplot.savefig(f\"{out_path}/MNIST_MLPexperiment_example{digit}_3.png\", dpi=1200)\n",
        "\n",
        "    x = x.transpose(1, 2).view(-1, 1, features, channels)  # 10x4\n",
        "    x = model.merge(x)\n",
        "    x = x.view(-1, features)\n",
        "\n",
        "    pyplot.bar(range(features), x[0].detach().cpu().numpy())\n",
        "    pyplot.show()\n",
        "    pyplot.bar(range(features), nn.functional.softmax(x[0], dim=0).detach().cpu().numpy())\n",
        "    pyplot.savefig(f\"{out_path}/MNIST_MLPexperiment_example{digit}_4.png\", dpi=1200)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8gvUC6avRvP0"
      },
      "source": [
        "## Hopfield as CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98,
          "referenced_widgets": [
            "853684230fb84317ad8e18d0879d6cc3",
            "705f0c7457594fb3a595c9f46b5687f9",
            "954c645dfa884a6d97017db6c34b8e3a",
            "2a28df1ec26846cd86c4fd4823f4850c",
            "866b66d34657471992762c32e7aa093a",
            "115aefffbc074502b4f98e18f700c9db",
            "06d6634b67024455b8127aea2300cecf",
            "fc4ff4915eb845a7b0748bde2c3f3f86",
            "fbaa3a2b3e8e4d2899dcb4f65a116cf8",
            "f7bcac9c8db541e6ac7074129b98892a",
            "07267b8b99a74e74a42933c92c03f836",
            "c6b1fa03a796466394eba4d406782deb",
            "eab860ef3f3d47bba8f8467b4e6f8d73",
            "cf9f8b5e90b24c2eb44a1dfa0630a1e5",
            "7fc9d7ea395b418e9b32546a893014b5",
            "df860cf747f24013a528c03148ad89ea",
            "2fa0c66c7b34426caaf058f23bc15ef3",
            "a4e9f592bcae4534bbae4e8f5f9e1e1e",
            "faafe9854d814712ae7c45dde816e972",
            "6e53282a11134f2692c7f8532eb494e3",
            "ef78d9a295ed4ebf8c2c6563d12e562d",
            "64b73c82b13446c286ccd0c4e95e691f",
            "afdb21b3048045d5a8abd0c121f21d16",
            "c567911cf8bd40ee8c7a61f490a5a5b9",
            "60b8c4649dc44fa29ae429253953c699",
            "c2d68e83ac334bb8aaf801c454736ba3",
            "81e8d75697ec458c9a9cc5cec1da416e",
            "44a5d96a009e4b0d95ceea2f043a4bfc",
            "08f85e1949c2463c99e5c650c05d01c6",
            "d23a97329b234817bc3060003c31f141",
            "659553c7472f4d2fa5e3f3d1f64ec036",
            "613cdca155334309a1eea255f643a826",
            "a743411c2e1446daa5f698880cecf192"
          ]
        },
        "id": "X7U3gu97RvP1",
        "outputId": "808d8214-3415-42d1-d4b8-2f2baf070074"
      },
      "outputs": [],
      "source": [
        "# @title training\n",
        "train_set = datasets.MNIST(mnist_contents, train=True, download=False, transform=transform)\n",
        "train_loader = data.DataLoader(train_set, batch_size=512, shuffle=True)\n",
        "\n",
        "class MyModel(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(MyModel, self).__init__()\n",
        "        self.hopfield = ConvHNN2d(1, 9, (5,5), iterations=2)\n",
        "        self.LAE = nn.Sequential(\n",
        "            nn.SiLU(),\n",
        "            nn.Conv2d(9, 3, (3,3), padding=(2,2)),\n",
        "            nn.SiLU(),\n",
        "            nn.ConvTranspose2d(3, 9, (3,3), padding=(2,2)),\n",
        "        )\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "\n",
        "        x = functional.pad(x, (4, 4, 4, 4), value=-1)\n",
        "        x = self.hopfield(x)\n",
        "        \n",
        "        x = self.LAE(x)\n",
        "\n",
        "        # rebuild image\n",
        "        x = nn.functional.softmax(x, dim=1)\n",
        "        x = nn.functional.conv_transpose2d(x,weight=self.hopfield._patterns)\n",
        "\n",
        "        # last adjustment\n",
        "        x = torch.clamp(x, -1, 1)\n",
        "        x = x[:, :, 4:36, 4:36]\n",
        "\n",
        "        return x\n",
        "\n",
        "model = MyModel()\n",
        "\n",
        "print(f\"trainable parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad)}\")\n",
        "\n",
        "loss_fn = nn.MSELoss()\n",
        "\n",
        "def reg_fn(model: MyModel) -> torch.Tensor:\n",
        "    reg = torch.tensor(0.0).to(torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
        "    reg += torch.mean(torch.abs(model.LAE[1].weight))\n",
        "    reg += torch.mean(torch.abs(model.LAE[3].weight))\n",
        "    return 0.01 * reg\n",
        "\n",
        "def input_converter(x: torch.Tensor) -> torch.Tensor:\n",
        "    x = x + torch.randn_like(x, device=x.device)*0.5  # final noise 1.0\n",
        "    x = x*2 - 1\n",
        "    return x\n",
        "\n",
        "def output_converter(y: torch.Tensor) -> torch.Tensor:\n",
        "    y = y*2 - 1\n",
        "    return y\n",
        "\n",
        "loss : List[float] = []\n",
        "reg : List[float] = []\n",
        "total : List[float] = []\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "l, r, t = trainer_autoencoder(\n",
        "    model,\n",
        "    train_loader,\n",
        "    loss_fn,\n",
        "    reg_fn,\n",
        "    optimizer,\n",
        "    20,\n",
        "    input_converter=input_converter,\n",
        "    output_converter=output_converter,\n",
        "    device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        ")\n",
        "loss += l\n",
        "reg += r\n",
        "total += t\n",
        "\n",
        "# show graph with evolution of loss and reg\n",
        "pyplot.bar(range(len(total)), total, label=\"Total\")\n",
        "pyplot.bar(range(len(loss)), loss, label=\"Loss\")\n",
        "pyplot.legend()\n",
        "pyplot.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "NXTV0-6HRvP1"
      },
      "outputs": [],
      "source": [
        "# @title testing\n",
        "test_set = datasets.MNIST(mnist_contents, train=False, download=False, transform=transform)\n",
        "test_loader = data.DataLoader(test_set, batch_size=2_048, shuffle=True)\n",
        "\n",
        "tester_autoencoder(model, test_loader, torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"), input_converter=input_converter, output_converter=output_converter)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "WoR6yLyORvP1"
      },
      "outputs": [],
      "source": [
        "# @title example\n",
        "model.to('cpu')\n",
        "img = next(iter(test_loader))[0][0].to('cpu')\n",
        "img = img.unsqueeze(0)\n",
        "img = input_converter(img)\n",
        "_y = model(img)\n",
        "\n",
        "fig, axs = pyplot.subplots(1, 2, figsize=(10, 5))\n",
        "axs[0].imshow(img[0,0].detach().cpu().numpy(), cmap='gray', vmin=-1, vmax=1)\n",
        "axs[0].axis('off')\n",
        "axs[1].imshow(_y[0,0].detach().cpu().numpy(), cmap='gray', vmin=-1, vmax=1)\n",
        "axs[1].axis('off')\n",
        "pyplot.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "DhnFaywBRvP1"
      },
      "outputs": [],
      "source": [
        "# @title analysis of the patterns for each convolution\n",
        "\n",
        "model.to(torch.device(\"cpu\"))\n",
        "\n",
        "# first convolution\n",
        "patterns = model.hopfield._patterns.data.view(9, 1, 5, 5).clone().numpy()\n",
        "fig, axs = pyplot.subplots(1, 9, figsize=(9*3, 1*3))\n",
        "p_max = patterns.max()\n",
        "p_min = patterns.min()\n",
        "r = max(abs(p_max), abs(p_min))\n",
        "for i in range(9):\n",
        "    axs[i].imshow(patterns[i,0], cmap='gray', vmin=-r, vmax=r)\n",
        "    axs[i].axis('off')\n",
        "pyplot.show()\n",
        "\n",
        "print(f\"beta: {torch.exp(model.hopfield._logbeta.data)}\")\n",
        "print(f\"bias: {model.hopfield._bias.data}\")\n",
        "\n",
        "# pattern's separation\n",
        "patterns = torch.tensor(patterns).view(9,-1)\n",
        "matrix = torch.einsum('ic, jc -> ij', patterns, patterns)\n",
        "pyplot.imshow(matrix.numpy(), cmap='gray')\n",
        "pyplot.colorbar()\n",
        "pyplot.show()\n",
        "\n",
        "matrix = torch.einsum('ic, jc -> ij', patterns/torch.norm(patterns, dim=1)[:,None], patterns/torch.norm(patterns, dim=1)[:,None])\n",
        "pyplot.imshow(matrix.numpy(), cmap='gray', vmin=-1, vmax=1)\n",
        "pyplot.colorbar()\n",
        "pyplot.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "ddJNSzOORvP1"
      },
      "outputs": [],
      "source": [
        "# @title evolution of an image through the network\n",
        "img = next(iter(test_loader))[0]\n",
        "img = input_converter(img)\n",
        "\n",
        "pyplot.imshow(img[0,0,:,:].to('cpu').numpy(), cmap='gray', vmin=-1, vmax=1)\n",
        "pyplot.axis('off')\n",
        "pyplot.savefig(f\"{out_path}/MNIST_CNN_image1.png\", dpi=1200)\n",
        "pyplot.show()\n",
        "\n",
        "x = img.clone()\n",
        "\n",
        "# filter\n",
        "x = functional.pad(x, (4, 4, 4, 4), value=-1)\n",
        "\n",
        "pyplot.imshow(x[0,0,:,:].to('cpu').numpy(), cmap='gray', vmin=-1, vmax=1)\n",
        "pyplot.axis('off')\n",
        "pyplot.savefig(f\"{out_path}/MNIST_CNN_image2.png\", dpi=1200)\n",
        "pyplot.show()\n",
        "\n",
        "x = model.hopfield(x)\n",
        "y = nn.functional.softmax(x, dim=1)\n",
        "fig, axs = pyplot.subplots(1, 9, figsize=(9*3, 1*3))\n",
        "for j in range(9):\n",
        "    axs[j].imshow(y.view(-1,1,9,36,36)[0,0,j].detach().to('cpu').numpy(), cmap='gray', vmin=0, vmax=y.max())\n",
        "    axs[j].axis('off')\n",
        "fig.savefig(f\"{out_path}/MNIST_CNN_image3.png\", dpi=1200)\n",
        "pyplot.show()\n",
        "\n",
        "# LAE\n",
        "x = model.LAE[0](x)\n",
        "x = model.LAE[1](x)  # latent code\n",
        "y = x.clone()\n",
        "fig, axs = pyplot.subplots(1, 3, figsize=(3*3, 1*3))\n",
        "for j in range(3):\n",
        "    axs[j].imshow(\n",
        "        y.view(-1,1,3,38,38)[0,0,j].detach().to('cpu').numpy(),\n",
        "        cmap='gray',\n",
        "        vmin=y[0,j].mean()-2*y[0,j].std(),\n",
        "        vmax=y[0,j].mean()+2*y[0,j].std()\n",
        "    )\n",
        "    axs[j].axis('off')\n",
        "fig.savefig(f\"{out_path}/MNIST_CNN_image4.png\", dpi=1200)\n",
        "pyplot.show()\n",
        "x = model.LAE[2](x)\n",
        "x = model.LAE[3](x)\n",
        "y = functional.softmax(x, dim=1)\n",
        "fig, axs = pyplot.subplots(1, 9, figsize=(9*3, 1*3))\n",
        "for j in range(9):\n",
        "    axs[j].imshow(y.view(-1,1,9,36,36)[0,0,j].detach().to('cpu').numpy(), cmap='gray', vmin=0, vmax=1)\n",
        "    axs[j].axis('off')\n",
        "fig.savefig(f\"{out_path}/MNIST_CNN_image5.png\", dpi=1200)\n",
        "pyplot.show()\n",
        "\n",
        "# ending\n",
        "x = nn.functional.softmax(x, dim=1)\n",
        "x = nn.functional.conv_transpose2d(\n",
        "    x,\n",
        "    weight=model.hopfield._patterns,\n",
        "    stride=model.hopfield.stride,\n",
        "    padding=model.hopfield.padding,\n",
        "    dilation=model.hopfield.dilation,\n",
        ")\n",
        "\n",
        "x = torch.clamp(x, -1, 1)\n",
        "x = x[:, :, 4:36, 4:36]\n",
        "\n",
        "pyplot.imshow(x[0,0].detach().to('cpu').numpy(), cmap='gray', vmin=0, vmax=1)\n",
        "pyplot.axis('off')\n",
        "pyplot.savefig(f\"{out_path}/MNIST_CNN_image6.png\", dpi=1200)\n",
        "pyplot.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NsrUoP3sRvP2"
      },
      "source": [
        "## Hopfield as VAE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title analyze patterns\n",
        "\n",
        "patterns = patterns.view(1, 30, 32*32)\n",
        "\n",
        "# compute M\n",
        "M = torch.norm(patterns, dim=2).max(dim=1).values\n",
        "print(f'{M=}')\n",
        "\n",
        "# compute Delta_i\n",
        "prod = torch.einsum('cin, cjn -> cij', patterns, patterns)\n",
        "diag = prod.diagonal(dim1=1, dim2=2)\n",
        "prod = diag.unsqueeze(2) - prod\n",
        "max_prod = prod.max(dim=2).values\n",
        "prod = prod + torch.diag_embed(max_prod)\n",
        "Delta = prod.min(dim=2).values\n",
        "\n",
        "print(f'{Delta=}')\n",
        "\n",
        "# compute min Delta\n",
        "Delta_min = Delta.min(dim=1).values\n",
        "\n",
        "# compute a value\n",
        "N = patterns.shape[1]\n",
        "a = 2/N + torch.log(2*N*(N-1)*M**2/Delta_min)\n",
        "if a.min() > 1:\n",
        "    num_of_iterations = 5\n",
        "    def f(x):\n",
        "        return a+torch.log(x)\n",
        "    x0 = 2*a.clone()\n",
        "    for _ in range(num_of_iterations):\n",
        "        x0 = f(x0)\n",
        "    beta_p = x0\n",
        "    x0 = (7*torch.ones_like(a) + x0)/8\n",
        "    beta = x0 / Delta_min\n",
        "else:\n",
        "    print(a)\n",
        "    raise ValueError(\"a must be greater than 1\")\n",
        "\n",
        "# compute S radius\n",
        "S_radius = 1 / (beta*N*M)\n",
        "print(f'{beta=}')\n",
        "print(f'{S_radius=}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title create initial status\n",
        "\n",
        "xi = torch.mean(patterns, dim=1).view(1, 1, 32*32) + torch.randn(5, 1, 32*32) * 10.0\n",
        "dist = (torch.einsum('bcn, cpn -> bcp', xi, patterns))**0.5\n",
        "dist_min = dist.min(dim=-1).values\n",
        "if (dist_min <= S_radius.view(1, -1)).any():\n",
        "    raise ValueError(\"dist_min must be greater than S_radius\")\n",
        "print(dist_min/32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title create a VHNN\n",
        "\n",
        "xi = patterns[:, [0,21,27], :].clone().detach()\n",
        "\n",
        "model = VHNN(1, 30, 32*32, beta_trainable=False, patterns_trainable=False, noise_trainable=False)\n",
        "model.update_patterns(patterns)\n",
        "model.update_beta(torch.ones_like(beta)*0.063)\n",
        "model.update_noise(torch.tensor([0.3]))\n",
        "\n",
        "x = xi.clone()\n",
        "x = x.view(xi.shape[1], 1, -1)\n",
        "\n",
        "# make frames for the animation\n",
        "frames = 4096\n",
        "states_image = torch.zeros(frames, xi.shape[1], 1, 32*32)\n",
        "nonoise_probs = torch.zeros(frames, xi.shape[1], 30)\n",
        "noise_probs = torch.zeros(frames, xi.shape[1], 30)\n",
        "L = torch.exp(model._logbeta/2).view(-1, 1, 1) * model._patterns\n",
        "x = torch.exp(model._logbeta/2).view(-1, 1, 1) * x\n",
        "for i in range(frames):\n",
        "    states_image[i,:,0,:] = x.view(xi.shape[1], 32*32)\n",
        "    x = torch.einsum('cfn, bcn -> bcf', L, x)\n",
        "    x = nn.functional.softmax(x, dim=2)\n",
        "    nonoise_probs[i,:,:] = x.view(xi.shape[1],30)\n",
        "    epsilon = torch.randn_like(x, device=x.device)\n",
        "    x = x + torch.exp(model._lognoise) * (x*(1-x))**0.5 * epsilon\n",
        "    noise_probs[i,:,:] = x.view(xi.shape[1],30)\n",
        "    x = torch.einsum('cfn, bcf -> bcn', L, x)\n",
        "x = torch.exp(-model._logbeta/2).view(1, -1, 1) * x\n",
        "\n",
        "# make the animation\n",
        "reduction_factor = 6\n",
        "states_image = states_image[::reduction_factor]\n",
        "nonoise_probs = nonoise_probs[::reduction_factor]\n",
        "noise_probs = noise_probs[::reduction_factor]\n",
        "frames = frames // reduction_factor\n",
        "\n",
        "fig, axs = pyplot.subplots(xi.shape[1], 3, figsize=(3*3, 2*xi.shape[1]))\n",
        "axs[0,0].set_title(\"Image\")\n",
        "axs[0,1].set_title(\"Probabilities without noise\")\n",
        "axs[0,2].set_title(\"Probabilities with noise\")\n",
        "for i in range(xi.shape[1]):\n",
        "    axs[i,0].axis('off')\n",
        "    axs[i,1].set_ylim(-1, 2)\n",
        "    axs[i,2].set_ylim(-1, 2)\n",
        "def update(frame):\n",
        "    for i in range(xi.shape[1]):\n",
        "        axs[i,0].clear()\n",
        "        axs[i,1].clear()\n",
        "        axs[i,2].clear()\n",
        "    axs[0,0].set_title(\"Image\")\n",
        "    axs[0,1].set_title(\"Probabilities without noise\")\n",
        "    axs[0,2].set_title(\"Probabilities with noise\")\n",
        "    for i in range(xi.shape[1]):\n",
        "        axs[i,0].axis('off')\n",
        "        axs[i,1].set_ylim(-1, 2)\n",
        "        axs[i,2].set_ylim(-1, 2)\n",
        "    for i in range(xi.shape[1]):\n",
        "        axs[i,0].imshow(states_image[frame,i].view(32, 32).detach().numpy(), cmap='gray')\n",
        "        axs[i,1].bar(range(30), nonoise_probs[frame,i].detach().numpy(), color='blue')\n",
        "        axs[i,2].bar(range(30), noise_probs[frame,i].detach().numpy(), color='red')\n",
        "    return axs\n",
        "\n",
        "ani = animation.FuncAnimation(fig, update, frames=frames, blit=False)\n",
        "ani.save(f\"{out_path}/VHNN_MNIST_animation.gif\", writer='pillow', fps=12)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "cell_execution_strategy": "setup",
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "06d6634b67024455b8127aea2300cecf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "07267b8b99a74e74a42933c92c03f836": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "08f85e1949c2463c99e5c650c05d01c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "115aefffbc074502b4f98e18f700c9db": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a28df1ec26846cd86c4fd4823f4850c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f7bcac9c8db541e6ac7074129b98892a",
            "placeholder": "\u200b",
            "style": "IPY_MODEL_07267b8b99a74e74a42933c92c03f836",
            "value": "\u20071/10\u2007[01:05&lt;09:48,\u200765.43s/it,\u2007loss=2.03,\u2007reg=0.0193]"
          }
        },
        "2fa0c66c7b34426caaf058f23bc15ef3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "44a5d96a009e4b0d95ceea2f043a4bfc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "60b8c4649dc44fa29ae429253953c699": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d23a97329b234817bc3060003c31f141",
            "max": 15,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_659553c7472f4d2fa5e3f3d1f64ec036",
            "value": 5
          }
        },
        "613cdca155334309a1eea255f643a826": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "64b73c82b13446c286ccd0c4e95e691f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "659553c7472f4d2fa5e3f3d1f64ec036": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6e53282a11134f2692c7f8532eb494e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "705f0c7457594fb3a595c9f46b5687f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_115aefffbc074502b4f98e18f700c9db",
            "placeholder": "\u200b",
            "style": "IPY_MODEL_06d6634b67024455b8127aea2300cecf",
            "value": "Epochs:\u2007\u200710%"
          }
        },
        "7fc9d7ea395b418e9b32546a893014b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ef78d9a295ed4ebf8c2c6563d12e562d",
            "placeholder": "\u200b",
            "style": "IPY_MODEL_64b73c82b13446c286ccd0c4e95e691f",
            "value": "\u200715/15\u2007[01:05&lt;00:00,\u2007\u20073.77s/it]"
          }
        },
        "81e8d75697ec458c9a9cc5cec1da416e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "853684230fb84317ad8e18d0879d6cc3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_705f0c7457594fb3a595c9f46b5687f9",
              "IPY_MODEL_954c645dfa884a6d97017db6c34b8e3a",
              "IPY_MODEL_2a28df1ec26846cd86c4fd4823f4850c"
            ],
            "layout": "IPY_MODEL_866b66d34657471992762c32e7aa093a"
          }
        },
        "866b66d34657471992762c32e7aa093a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "954c645dfa884a6d97017db6c34b8e3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fc4ff4915eb845a7b0748bde2c3f3f86",
            "max": 10,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fbaa3a2b3e8e4d2899dcb4f65a116cf8",
            "value": 1
          }
        },
        "a4e9f592bcae4534bbae4e8f5f9e1e1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a743411c2e1446daa5f698880cecf192": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "afdb21b3048045d5a8abd0c121f21d16": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c567911cf8bd40ee8c7a61f490a5a5b9",
              "IPY_MODEL_60b8c4649dc44fa29ae429253953c699",
              "IPY_MODEL_c2d68e83ac334bb8aaf801c454736ba3"
            ],
            "layout": "IPY_MODEL_81e8d75697ec458c9a9cc5cec1da416e"
          }
        },
        "c2d68e83ac334bb8aaf801c454736ba3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_613cdca155334309a1eea255f643a826",
            "placeholder": "\u200b",
            "style": "IPY_MODEL_a743411c2e1446daa5f698880cecf192",
            "value": "\u20075/15\u2007[00:21&lt;00:43,\u2007\u20074.33s/it]"
          }
        },
        "c567911cf8bd40ee8c7a61f490a5a5b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_44a5d96a009e4b0d95ceea2f043a4bfc",
            "placeholder": "\u200b",
            "style": "IPY_MODEL_08f85e1949c2463c99e5c650c05d01c6",
            "value": "Batches:\u2007\u200733%"
          }
        },
        "c6b1fa03a796466394eba4d406782deb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_eab860ef3f3d47bba8f8467b4e6f8d73",
              "IPY_MODEL_cf9f8b5e90b24c2eb44a1dfa0630a1e5",
              "IPY_MODEL_7fc9d7ea395b418e9b32546a893014b5"
            ],
            "layout": "IPY_MODEL_df860cf747f24013a528c03148ad89ea"
          }
        },
        "cf9f8b5e90b24c2eb44a1dfa0630a1e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_faafe9854d814712ae7c45dde816e972",
            "max": 15,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6e53282a11134f2692c7f8532eb494e3",
            "value": 15
          }
        },
        "d23a97329b234817bc3060003c31f141": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df860cf747f24013a528c03148ad89ea": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "eab860ef3f3d47bba8f8467b4e6f8d73": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2fa0c66c7b34426caaf058f23bc15ef3",
            "placeholder": "\u200b",
            "style": "IPY_MODEL_a4e9f592bcae4534bbae4e8f5f9e1e1e",
            "value": "Batches:\u2007100%"
          }
        },
        "ef78d9a295ed4ebf8c2c6563d12e562d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f7bcac9c8db541e6ac7074129b98892a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "faafe9854d814712ae7c45dde816e972": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fbaa3a2b3e8e4d2899dcb4f65a116cf8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fc4ff4915eb845a7b0748bde2c3f3f86": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
